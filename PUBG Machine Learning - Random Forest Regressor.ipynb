{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# machine learning imports\nimport sklearn as skl\nimport pandas as pd\nfrom sklearn import preprocessing\n#from sklearn.linear_model import LinearRegression # does not auto import\n#from sklearn.linear_model import Ridge # does not auto import\n#from sklearn.linear_model import Lasso # does not auto import\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error # also does not auto import\nfrom sklearn.model_selection import train_test_split\n#from sklearn.externals import joblib # needed to save classes\nimport numpy as np\n#import matplotlib.pyplot as plt\n#import seaborn as sns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# optional suppression of warning\nimport warnings\nwarnings.filterwarnings('ignore')\n# warnings.filterwarnings(action='once')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a55d24d7af1045bfa7c5b003679cbcaf7c5fc4df"
      },
      "cell_type": "code",
      "source": "# set up our feature engineering labels\ne_labels = ['matchId','groupId','killPlace', 'boosts', 'walkDistance', 'weaponsAcquired', 'damageDealt', 'heals', \n                        'kills', 'longestKill', 'killStreaks', 'rideDistance', 'winPlacePerc', 'matchType']\n\n# list of the variables discovered to be significant in data analysis\nvariables = ['killPlace', 'boosts', 'walkDistance', 'weaponsAcquired', 'damageDealt', 'heals', \n             'kills', 'longestKill', 'killStreaks', 'rideDistance','rampage', 'lethality', \n             'items', 'totalDistance','winPlacePerc']\n\n\n\ndef feature_engineering(pubg_data):\n    '''FEATURE ENGINEERING\n    GIVEN: a PUBG dataframe which must have a dummy 'winPlacePerc' column if a test set\n    Conduct data engineering including:\n    producing group data, normalising data with relevant match stats, clipping extreme results\n    RETURNS: pubg_x dataframe consisting of feature engineered input columns\n             pubg_y dataframe with target values (0 dummy frame if this is a test set)\n    '''\n\n    # total the pickups\n    pubg_data['items'] = pubg_data['heals'] + pubg_data['boosts'] + pubg_data[\"weaponsAcquired\"]\n    \n    # total the distance\n    pubg_data['totalDistance'] = pubg_data['rideDistance'] + pubg_data['swimDistance'] + pubg_data['walkDistance']\n\n    # estimate accuracy of players\n    pubg_data['lethality'] = pubg_data['headshotKills'] / pubg_data['kills']\n    pubg_data['lethality'].replace(np.inf, 0, inplace=True)\n    pubg_data['lethality'].fillna(0, inplace=True)\n    \n    # estimate how players behave in shootouts\n    pubg_data['rampage'] = pubg_data['killStreaks'] / pubg_data['kills']\n    pubg_data['rampage'].replace(np.inf, 0, inplace=True)\n    pubg_data['rampage'].fillna(0, inplace=True)\n    \n    # reduce dataframe to the columns we want to use\n    # pubg_data = pubg_data[e_labels]\n\n    # use groupby to get means for team\n    pubg_group_means = pubg_data.groupby(['matchId','groupId']).mean().reset_index()\n\n    # use groupby to get means of matches\n    pubg_match_means = pubg_data.groupby(['matchId']).mean().reset_index()\n\n    # merge back in leaving columns unchanged for one set to allow for future suffixing (only affects shared columns)\n    pubg_engineered = pd.merge(pubg_data, pubg_group_means, \n                               suffixes=[\"\", \"_group\"], how = \"left\", on = ['matchId', 'groupId']) \n    pubg_engineered = pd.merge(pubg_engineered, pubg_match_means, \n                               suffixes=[\"_player\", \"_match\"], how = \"left\", on = ['matchId'])\n\n    # norm the player variables\n    for variable in variables:\n        pubg_engineered[variable+'_norm'] = pubg_engineered[variable+'_player']/(pubg_engineered[variable+'_match']+0.1)\n\n    # norm the group variables\n    for variable in variables:\n        pubg_engineered[variable+'_g_norm'] = pubg_engineered[variable+'_group']/(pubg_engineered[variable+'_match']+0.1)\n        \n    # one hot encode the matchTypes since different matches may follow different logics\n    one_hot = pd.get_dummies(pubg_engineered['matchType'])\n    # Drop column B as it is now encoded\n    pubg_engineered = pubg_engineered.drop('matchType',axis = 1)\n    # Join the encoded df\n    pubg_engineered = pubg_engineered.join(one_hot)\n\n    # setting up our basic data\n    pubg_engineered = pubg_engineered.reset_index(drop=True)\n    \n    return pubg_engineered",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd0a2fc306ab51c7bf95edeba700d890c6323c62"
      },
      "cell_type": "code",
      "source": "# labels for desired columns for dataset to feed to model\n# use normed values for stats except for rideDistance where correlation worsens\n# use category variables for game types where this information assists the model\nlabels = ['killPlace_norm', 'boosts_norm','walkDistance_norm', 'weaponsAcquired_norm', \n          'damageDealt_norm','heals_norm', 'kills_norm', 'longestKill_norm',\n          'killStreaks_norm', 'rideDistance_player', 'killPlace_g_norm', 'boosts_g_norm', \n          'walkDistance_g_norm', 'weaponsAcquired_g_norm', 'damageDealt_g_norm', \n          'heals_g_norm','kills_g_norm', 'longestKill_g_norm', 'killStreaks_g_norm',\n          'rampage_norm', 'lethality_norm', 'duo', 'duo-fpp', 'solo', 'solo-fpp', \n          'squad','squad-fpp']\n\ndef feature_selection(pubg_data):\n    # create raw input  data\n    pubg_x = pubg_data[labels]\n\n    # clip extreme outliers on a per column basis \n    pubg_x = pubg_x.clip(lower=None, upper= pubg_x.quantile(0.999), axis = 1)\n\n    # set up our target data (not needed for test, so creates a dummy variable\n    \n\n    #return values\n    return pubg_x",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-output": false,
        "trusted": true,
        "_uuid": "813db92cab4303f785e50c130c3bc07641ba5913"
      },
      "cell_type": "code",
      "source": "# import our training data\npubg_data = pd.read_csv('../input/train_V2.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1253aa6d59e87d72174f3983186948c8de99a20"
      },
      "cell_type": "code",
      "source": "# clean up our data (drop invalid row)\npubg_data = pubg_data.dropna()\npubg_y = pubg_data['winPlacePerc']\n\n# SUPPRESS chained assignment warnings\npd.options.mode.chained_assignment = None\n\n# perform feature engineering on the dataset\npubg_engineered = feature_engineering(pubg_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1782ef913ea65f978372f5228142522c96f4389"
      },
      "cell_type": "code",
      "source": "# do our feature engineering and split off our target variable\npubg_x = feature_selection(pubg_engineered)\n\n# save memory before running training\ndel(pubg_data)\ndel(pubg_engineered)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab6ad5e9b568ee46bcbc9e557de3aa4bbc0f7e03",
        "_kg_hide-output": false
      },
      "cell_type": "code",
      "source": "# now lets scale data to ensure column scales do not skew results\nscaler = skl.preprocessing.StandardScaler().fit(pubg_x)\n#joblib.dump(scaler, 'pubg_scaler.joblib') \n\n# lets look at the head again - we need to convert back to dataframe from numpy array though\npubg_x = pd.DataFrame(scaler.transform(pubg_x), columns= labels)\n# having a scaler object will let us use it on the test data too :-)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4e5c386d1148795d83d0ca01e6b2137e23dc35d"
      },
      "cell_type": "code",
      "source": "# partition into train and validation (only needed during development)\n# pubg_x_train, pubg_x_valid, pubg_y_train, pubg_y_valid = train_test_split(pubg_x, pubg_y, random_state = 9)\n\n# reassign pubg_x and pubg_y to provide continuity with development variable names\npubg_x_train = pubg_x \npubg_y_train = pubg_y\n\n# save memory before running training\ndel(pubg_x)\ndel(pubg_y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "df4882cdad4cbda05f8df2e1ed264db94570edd3"
      },
      "cell_type": "code",
      "source": "# now lets create the model\nmodel_rf = RandomForestRegressor(n_estimators=32, oob_score=False, random_state=0, n_jobs =-1, verbose = 2)\n\n# and fit it...\nmodel_rf.fit(pubg_x_train, pubg_y_train)\n\n# now lets test how well it fits training data \n# obviously the test data will not achieve this level of fit but it checks for obvious errors\npredict_train_rf = model_rf.predict(pubg_x_train)\nprint('Mean absolute error for the training set using random forest regressor model %.4f' %\n      mean_absolute_error(pubg_y_train, np.clip(predict_train_rf, 0, 1)))\n# test against our validation set (during development only)\n# predict_train_rf = model_rf.predict(pubg_x_valid)\n# print('Mean absolute error for the training set using random forest regressor model %.4f' %\n#       mean_absolute_error(pubg_y_valid, np.clip(predict_train_rf, 0, 1)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7aed7164f9ad348378654f93054afa1cbd12f23d"
      },
      "cell_type": "code",
      "source": "# save memory before loading test data\ndel(pubg_x_train)\ndel(pubg_y_train)\ndel(predict_train_rf)\n# del(pubg_x_valid)\n# del(pubg_y_valid)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dfeaa633a21ef3107266d40068a7b9ac4a39db86"
      },
      "cell_type": "code",
      "source": "# now we are ready to read in the test data\npubg_data_test = pd.read_csv('../input/test_V2.csv')\n#print(pubg_data_test.isnull().sum()) # no NaNs\n\n# add a dummy winPlacePerc column to pubg_data_test so we can use our feature engineering function\npubg_data_test['winPlacePerc'] = 0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e733f18c47cc638804705f37365a8f60a19c7e75"
      },
      "cell_type": "code",
      "source": "# do our feature engineering (NB pubg_y is a dummy return here)\npubg_engineered_t = feature_engineering(pubg_data_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e2abcfa1fe1228e136cec7f9a2ed5d1ef0c7c5e6"
      },
      "cell_type": "code",
      "source": "# do our feature selection\npubg_x_t = feature_selection(pubg_engineered_t)\n\n# save space before running prediction\ndel(pubg_engineered_t)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68d1c6b697a4779a41b899e1d24f53cecadc561a"
      },
      "cell_type": "code",
      "source": "#use our scaler on the test data too\npubg_x_test = pd.DataFrame(scaler.transform(pubg_x_t), columns= labels)\n\n# then make predictions\npredict_test_rf_t = model_rf.predict(pubg_x_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9ec8d06a5422354ca1826dbeb8af4032f158b50"
      },
      "cell_type": "code",
      "source": "# and clip outlying values as they cannot be correct\npredict_test_rf_clip_t = np.clip(predict_test_rf_t, 0, 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c065e7a52b89281ec42803179eda32a55d27eaf"
      },
      "cell_type": "code",
      "source": "# prepare output\npredict_test_rf_df_t = pd.DataFrame(data= predict_test_rf_clip_t, columns=['winPlacePerc'])\noutput_df = pd.merge(pubg_data_test[\"Id\"].to_frame(),predict_test_rf_df_t['winPlacePerc'].to_frame(), left_index=True, right_index=True)\noutput_df.head()\n\n# write output\noutput_df.to_csv(\"submission.csv\", index = False, index_label=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ede900a140fede045e9cd3f005110256870e12ec"
      },
      "cell_type": "code",
      "source": "# release unneeded memory\ndel(pubg_x_test)\ndel(pubg_data_test)\ndel(predict_test_rf_clip_t)\ndel(predict_test_rf_df_t)\ndel(output_df)\ndel(predict_test_rf_t)\n\nprint(\"DONE\")",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}